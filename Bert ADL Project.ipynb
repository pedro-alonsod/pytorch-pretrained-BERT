{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.circleci', '.git', '.github', '.gitignore', '.ipynb_checkpoints', 'askreddit_data.json', 'Bert ADL Project.ipynb', 'docker', 'docs', 'examples', 'hubconf.py', 'hubconfs', 'LICENSE', 'MANIFEST.in', 'notebooks', 'pytorch_pretrained_bert', 'README.md', 'requirements.txt', 'samples', 'setup.py', 'tests', 'uncased_askreddit_data.tsv']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open('./askreddit_data.json', 'r'))\n",
    "\n",
    "# ask_reddit_data =  pd.read_json('./askreddit_data.json')\n",
    "# ask_reddit_data = json_normalize(data)\n",
    "uncased_ask_reddit_data = pd.read_csv('./uncased_askreddit_data.tsv', sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ask_reddit_data.head()#['comments'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>submission score</th>\n",
       "      <th>comment score</th>\n",
       "      <th>submission id</th>\n",
       "      <th>comment id</th>\n",
       "      <th>title (string #1)</th>\n",
       "      <th>comment (string#2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80513</td>\n",
       "      <td>25495</td>\n",
       "      <td>bn3bpz</td>\n",
       "      <td>en27b8v</td>\n",
       "      <td>would you support a mandatory environmental se...</td>\n",
       "      <td>not mandatory, but there was a voluntary progr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80513</td>\n",
       "      <td>4686</td>\n",
       "      <td>bn3bpz</td>\n",
       "      <td>en2anug</td>\n",
       "      <td>would you support a mandatory environmental se...</td>\n",
       "      <td>i feel like instead of forcing people to do so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80513</td>\n",
       "      <td>2041</td>\n",
       "      <td>bn3bpz</td>\n",
       "      <td>en254lj</td>\n",
       "      <td>would you support a mandatory environmental se...</td>\n",
       "      <td>i wouldn't make it mandatory but maybe optiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80513</td>\n",
       "      <td>608</td>\n",
       "      <td>bn3bpz</td>\n",
       "      <td>en2gacy</td>\n",
       "      <td>would you support a mandatory environmental se...</td>\n",
       "      <td>we already have americorps, where you serve fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80513</td>\n",
       "      <td>310</td>\n",
       "      <td>bn3bpz</td>\n",
       "      <td>en2p5ro</td>\n",
       "      <td>would you support a mandatory environmental se...</td>\n",
       "      <td>i feel like forcing people to do it will just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>80513</td>\n",
       "      <td>2580</td>\n",
       "      <td>bn3bpz</td>\n",
       "      <td>en22x9q</td>\n",
       "      <td>would you support a mandatory environmental se...</td>\n",
       "      <td>mandatory servitude is never a step in the rig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>80513</td>\n",
       "      <td>9453</td>\n",
       "      <td>bn3bpz</td>\n",
       "      <td>en21ky7</td>\n",
       "      <td>would you support a mandatory environmental se...</td>\n",
       "      <td>i don't support involuntary anything</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80513</td>\n",
       "      <td>5045</td>\n",
       "      <td>bn3bpz</td>\n",
       "      <td>en22jzh</td>\n",
       "      <td>would you support a mandatory environmental se...</td>\n",
       "      <td>that sounds like slavery with extra steps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>80513</td>\n",
       "      <td>141</td>\n",
       "      <td>bn3bpz</td>\n",
       "      <td>en32fz3</td>\n",
       "      <td>would you support a mandatory environmental se...</td>\n",
       "      <td>this is the most reddit thing i've read in a l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>80513</td>\n",
       "      <td>18</td>\n",
       "      <td>bn3bpz</td>\n",
       "      <td>en4942i</td>\n",
       "      <td>would you support a mandatory environmental se...</td>\n",
       "      <td>i oppose any form of conscription.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>80513</td>\n",
       "      <td>40</td>\n",
       "      <td>bn3bpz</td>\n",
       "      <td>en2ji7k</td>\n",
       "      <td>would you support a mandatory environmental se...</td>\n",
       "      <td>posting this in us time zones was a bold move</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>80513</td>\n",
       "      <td>574</td>\n",
       "      <td>bn3bpz</td>\n",
       "      <td>en276bu</td>\n",
       "      <td>would you support a mandatory environmental se...</td>\n",
       "      <td>i don't support forced service of any kind. th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>80513</td>\n",
       "      <td>1619</td>\n",
       "      <td>bn3bpz</td>\n",
       "      <td>en239dq</td>\n",
       "      <td>would you support a mandatory environmental se...</td>\n",
       "      <td>no. some of us need to earn a living. who's go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>80513</td>\n",
       "      <td>127</td>\n",
       "      <td>bn3bpz</td>\n",
       "      <td>en2jy22</td>\n",
       "      <td>would you support a mandatory environmental se...</td>\n",
       "      <td>no, for pretty much every reason already given...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>80513</td>\n",
       "      <td>182</td>\n",
       "      <td>bn3bpz</td>\n",
       "      <td>en1vqzv</td>\n",
       "      <td>would you support a mandatory environmental se...</td>\n",
       "      <td>miltary is not mandatory, its also not a few m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>80513</td>\n",
       "      <td>106</td>\n",
       "      <td>bn3bpz</td>\n",
       "      <td>en1vtlq</td>\n",
       "      <td>would you support a mandatory environmental se...</td>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>80513</td>\n",
       "      <td>285</td>\n",
       "      <td>bn3bpz</td>\n",
       "      <td>en2a4k8</td>\n",
       "      <td>would you support a mandatory environmental se...</td>\n",
       "      <td>so the old people who ruined the environment c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>80513</td>\n",
       "      <td>58</td>\n",
       "      <td>bn3bpz</td>\n",
       "      <td>en2efyz</td>\n",
       "      <td>would you support a mandatory environmental se...</td>\n",
       "      <td>mandatory? no, especially not based on a milit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>80513</td>\n",
       "      <td>170</td>\n",
       "      <td>bn3bpz</td>\n",
       "      <td>en22kxk</td>\n",
       "      <td>would you support a mandatory environmental se...</td>\n",
       "      <td>no. i don't support mandatory anything.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>80513</td>\n",
       "      <td>7</td>\n",
       "      <td>bn3bpz</td>\n",
       "      <td>en491u7</td>\n",
       "      <td>would you support a mandatory environmental se...</td>\n",
       "      <td>no. for the same reason i don't believe in the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    submission score  comment score submission id comment id  \\\n",
       "0              80513          25495        bn3bpz    en27b8v   \n",
       "1              80513           4686        bn3bpz    en2anug   \n",
       "2              80513           2041        bn3bpz    en254lj   \n",
       "3              80513            608        bn3bpz    en2gacy   \n",
       "4              80513            310        bn3bpz    en2p5ro   \n",
       "5              80513           2580        bn3bpz    en22x9q   \n",
       "6              80513           9453        bn3bpz    en21ky7   \n",
       "7              80513           5045        bn3bpz    en22jzh   \n",
       "8              80513            141        bn3bpz    en32fz3   \n",
       "9              80513             18        bn3bpz    en4942i   \n",
       "10             80513             40        bn3bpz    en2ji7k   \n",
       "11             80513            574        bn3bpz    en276bu   \n",
       "12             80513           1619        bn3bpz    en239dq   \n",
       "13             80513            127        bn3bpz    en2jy22   \n",
       "14             80513            182        bn3bpz    en1vqzv   \n",
       "15             80513            106        bn3bpz    en1vtlq   \n",
       "16             80513            285        bn3bpz    en2a4k8   \n",
       "17             80513             58        bn3bpz    en2efyz   \n",
       "18             80513            170        bn3bpz    en22kxk   \n",
       "19             80513              7        bn3bpz    en491u7   \n",
       "\n",
       "                                    title (string #1)  \\\n",
       "0   would you support a mandatory environmental se...   \n",
       "1   would you support a mandatory environmental se...   \n",
       "2   would you support a mandatory environmental se...   \n",
       "3   would you support a mandatory environmental se...   \n",
       "4   would you support a mandatory environmental se...   \n",
       "5   would you support a mandatory environmental se...   \n",
       "6   would you support a mandatory environmental se...   \n",
       "7   would you support a mandatory environmental se...   \n",
       "8   would you support a mandatory environmental se...   \n",
       "9   would you support a mandatory environmental se...   \n",
       "10  would you support a mandatory environmental se...   \n",
       "11  would you support a mandatory environmental se...   \n",
       "12  would you support a mandatory environmental se...   \n",
       "13  would you support a mandatory environmental se...   \n",
       "14  would you support a mandatory environmental se...   \n",
       "15  would you support a mandatory environmental se...   \n",
       "16  would you support a mandatory environmental se...   \n",
       "17  would you support a mandatory environmental se...   \n",
       "18  would you support a mandatory environmental se...   \n",
       "19  would you support a mandatory environmental se...   \n",
       "\n",
       "                                   comment (string#2)  \n",
       "0   not mandatory, but there was a voluntary progr...  \n",
       "1   i feel like instead of forcing people to do so...  \n",
       "2   i wouldn't make it mandatory but maybe optiona...  \n",
       "3   we already have americorps, where you serve fo...  \n",
       "4   i feel like forcing people to do it will just ...  \n",
       "5   mandatory servitude is never a step in the rig...  \n",
       "6                i don't support involuntary anything  \n",
       "7           that sounds like slavery with extra steps  \n",
       "8   this is the most reddit thing i've read in a l...  \n",
       "9                  i oppose any form of conscription.  \n",
       "10      posting this in us time zones was a bold move  \n",
       "11  i don't support forced service of any kind. th...  \n",
       "12  no. some of us need to earn a living. who's go...  \n",
       "13  no, for pretty much every reason already given...  \n",
       "14  miltary is not mandatory, its also not a few m...  \n",
       "15                                          [deleted]  \n",
       "16  so the old people who ruined the environment c...  \n",
       "17  mandatory? no, especially not based on a milit...  \n",
       "18            no. i don't support mandatory anything.  \n",
       "19  no. for the same reason i don't believe in the...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncased_ask_reddit_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache, downloading to C:\\Users\\pedalo\\AppData\\Local\\Temp\\tmprwtohdv4\n",
      "100%|███████████████████████████████████████████████████████████████████████| 231508/231508 [00:00<00:00, 625696.28B/s]\n",
      "INFO:pytorch_pretrained_bert.file_utils:copying C:\\Users\\pedalo\\AppData\\Local\\Temp\\tmprwtohdv4 to cache at C:\\Users\\pedalo\\.cache\\torch\\pytorch_pretrained_bert\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "INFO:pytorch_pretrained_bert.file_utils:creating metadata file for C:\\Users\\pedalo\\.cache\\torch\\pytorch_pretrained_bert\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "INFO:pytorch_pretrained_bert.file_utils:removing temp file C:\\Users\\pedalo\\AppData\\Local\\Temp\\tmprwtohdv4\n",
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\\Users\\pedalo\\.cache\\torch\\pytorch_pretrained_bert\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'who', 'was', 'jim', 'henson', '?', '[SEP]', 'jim', 'henson', 'was', 'a', 'puppet', '##eer', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# Tokenized input\n",
    "text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask a token that we will try to predict back with `BertForMaskedLM`\n",
    "masked_index = 8\n",
    "tokenized_text[masked_index] = '[MASK]'\n",
    "assert tokenized_text == ['[CLS]', 'who', 'was', 'jim', 'henson', '?', '[SEP]', 'jim', '[MASK]', 'was', 'a', 'puppet', '##eer', '[SEP]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert token to vocabulary indices\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "# Define sentence A and B indices associated to 1st and 2nd sentences (see paper)\n",
    "segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "print(tokens_tensor)\n",
    "print(segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\\Users\\pedalo\\.cache\\torch\\pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO:pytorch_pretrained_bert.modeling:extracting archive file C:\\Users\\pedalo\\.cache\\torch\\pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\\Users\\pedalo\\AppData\\Local\\Temp\\tmpyib2v119\n",
      "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "\n",
    "# If you have a GPU, put everything on cuda\n",
    "if torch.cuda.is_available() == True:\n",
    "    tokens_tensor = tokens_tensor.to('cuda')\n",
    "    segments_tensors = segments_tensors.to('cuda')\n",
    "    model.to('cuda')\n",
    "\n",
    "# Predict hidden states features for each layer\n",
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
    "# We have a hidden states for each of the 12 layers in model bert-base-uncased\n",
    "assert len(encoded_layers) == 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at C:\\Users\\pedalo\\.cache\\torch\\pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO:pytorch_pretrained_bert.modeling:extracting archive file C:\\Users\\pedalo\\.cache\\torch\\pytorch_pretrained_bert\\9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir C:\\Users\\pedalo\\AppData\\Local\\Temp\\tmpihu8lrez\n",
      "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:pytorch_pretrained_bert.modeling:Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 14, 30522])\n",
      "27227\n",
      "henson\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "\n",
    "# If you have a GPU, put everything on cuda\n",
    "if torch.cuda.is_available() == True:\n",
    "    tokens_tensor = tokens_tensor.to('cuda')\n",
    "    segments_tensors = segments_tensors.to('cuda')\n",
    "    model.to('cuda')\n",
    "\n",
    "# Predict all tokens\n",
    "with torch.no_grad():\n",
    "    predictions = model(tokens_tensor, segments_tensors)\n",
    "    print(predictions.size())\n",
    "# confirm we were able to predict 'henson'\n",
    "predicted_index = torch.argmax(predictions[0, masked_index]).item()\n",
    "predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "assert predicted_token == 'henson'\n",
    "print(predicted_index)\n",
    "print(predicted_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
